{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. SETUP MODEL ---\n",
    "# Qwen 2.5 (0.5B) is great for following strict formatting instructions\n",
    "llm = ChatOllama(model=\"qwen2.5:0.5b\", temperature=0.2)\n",
    "\n",
    "# --- 2. DEFINE STATE ---\n",
    "# We need to track the inputs (what the user wants) and the output (the plan)\n",
    "class StudyState(TypedDict):\n",
    "    subjects: List[str]   # e.g., [\"Math\", \"Physics\", \"History\"]\n",
    "    hours_available: int  # e.g., 5\n",
    "    study_plan: str       # The generated schedule\n",
    "\n",
    "# --- 3. DEFINE NODES ---\n",
    "\n",
    "def planner_node(state: StudyState):\n",
    "    subjects = state[\"subjects\"]\n",
    "    hours = state[\"hours_available\"]\n",
    "    \n",
    "    # We create a prompt that forces the LLM to be a \"Scheduler\"\n",
    "    # We ask it to break down the time and include breaks.\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are an expert academic study planner.\n",
    "        Create a strict study schedule based on the following constraints:\n",
    "        \n",
    "        Subjects to study: {subjects}\n",
    "        Total Time Available: {hours} hours\n",
    "        \n",
    "        Rules:\n",
    "        1. Divide the time fairly among the subjects.\n",
    "        2. Include short 5-10 minute breaks between sessions.\n",
    "        3. Output the plan as a clean list with time slots (assuming start time is Now).\n",
    "        4. Do not talk. Just output the schedule.\n",
    "        \n",
    "        Schedule:\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Format the list of subjects into a string\n",
    "    subjects_str = \", \".join(subjects)\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"subjects\": subjects_str, \"hours\": hours})\n",
    "    \n",
    "    print(\"âœ… Plan Generated!\")\n",
    "    return {\"study_plan\": response.content}\n",
    "\n",
    "# --- 4. BUILD GRAPH ---\n",
    "\n",
    "workflow = StateGraph(StudyState)\n",
    "\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.set_entry_point(\"planner\")\n",
    "workflow.add_edge(\"planner\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- 5. RUN IT ---\n",
    "\n",
    "# Scenario: A student with a heavy exam load tomorrow\n",
    "print(\"--- ðŸ“š GENERATING EXAM STUDY PLAN ---\")\n",
    "inputs = {\n",
    "    \"subjects\": [\"Linear Algebra\", \"Data Structures\", \"Economics\"],\n",
    "    \"hours_available\": 6\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" YOUR PLAN \" + \"=\"*20)\n",
    "print(result['study_plan'])\n",
    "print(\"=\"*51)\n",
    "\n",
    "# Scenario: A light weekend study session\n",
    "print(\"\\n\\n--- â˜• GENERATING WEEKEND REFRESHER PLAN ---\")\n",
    "inputs = {\n",
    "    \"subjects\": [\"Python Practice\", \"Reading Novel\"],\n",
    "    \"hours_available\": 2\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" YOUR PLAN \" + \"=\"*20)\n",
    "print(result['study_plan'])\n",
    "print(\"=\"*51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3cc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
