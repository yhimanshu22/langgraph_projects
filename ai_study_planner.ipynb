{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49c6afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ“š GENERATING EXAM STUDY PLAN ---\n",
      "âœ… Plan Generated!\n",
      "\n",
      "==================== YOUR PLAN ====================\n",
      "Sure, here's a strict study schedule based on your constraints:\n",
      "\n",
      "1. **Now** - Start studying Linear Algebra.\n",
      "2. **5 minutes** - Take a short break.\n",
      "3. **10 minutes** - Continue with Data Structures.\n",
      "4. **15 minutes** - Take a short break.\n",
      "5. **20 minutes** - Continue with Economics.\n",
      "6. **15 minutes** - Take a short break.\n",
      "7. **5 minutes** - End the day by studying Linear Algebra again.\n",
      "\n",
      "This schedule ensures that you get 5-10 minutes of breaks between each subject, which helps maintain productivity and prevents burnout.\n",
      "===================================================\n",
      "\n",
      "\n",
      "--- â˜• GENERATING WEEKEND REFRESHER PLAN ---\n",
      "âœ… Plan Generated!\n",
      "\n",
      "==================== YOUR PLAN ====================\n",
      "Sure, here's a strict study schedule for Python Practice and Reading Novel:\n",
      "\n",
      "1. Start Time: Now\n",
      "\n",
      "2. Break Time: 5 minutes\n",
      "\n",
      "3. Study Time:\n",
      "   - Python Practice (5 minutes)\n",
      "   - Reading Novel (5 minutes)\n",
      "\n",
      "4. End Time: Now + 10 minutes\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. SETUP MODEL ---\n",
    "# Qwen 2.5 (0.5B) is great for following strict formatting instructions\n",
    "llm = ChatOllama(model=\"qwen2.5:0.5b\", temperature=0.2)\n",
    "\n",
    "# --- 2. DEFINE STATE ---\n",
    "# We need to track the inputs (what the user wants) and the output (the plan)\n",
    "class StudyState(TypedDict):\n",
    "    subjects: List[str]   # e.g., [\"Math\", \"Physics\", \"History\"]\n",
    "    hours_available: int  # e.g., 5\n",
    "    study_plan: str       # The generated schedule\n",
    "\n",
    "# --- 3. DEFINE NODES ---\n",
    "\n",
    "def planner_node(state: StudyState):\n",
    "    subjects = state[\"subjects\"]\n",
    "    hours = state[\"hours_available\"]\n",
    "    \n",
    "    # We create a prompt that forces the LLM to be a \"Scheduler\"\n",
    "    # We ask it to break down the time and include breaks.\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are an expert academic study planner.\n",
    "        Create a strict study schedule based on the following constraints:\n",
    "        \n",
    "        Subjects to study: {subjects}\n",
    "        Total Time Available: {hours} hours\n",
    "        \n",
    "        Rules:\n",
    "        1. Divide the time fairly among the subjects.\n",
    "        2. Include short 5-10 minute breaks between sessions.\n",
    "        3. Output the plan as a clean list with time slots (assuming start time is Now).\n",
    "        4. Do not talk. Just output the schedule.\n",
    "        \n",
    "        Schedule:\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Format the list of subjects into a string\n",
    "    subjects_str = \", \".join(subjects)\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"subjects\": subjects_str, \"hours\": hours})\n",
    "    \n",
    "    print(\"âœ… Plan Generated!\")\n",
    "    return {\"study_plan\": response.content}\n",
    "\n",
    "# --- 4. BUILD GRAPH ---\n",
    "\n",
    "workflow = StateGraph(StudyState)\n",
    "\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.set_entry_point(\"planner\")\n",
    "workflow.add_edge(\"planner\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- 5. RUN IT ---\n",
    "\n",
    "# Scenario: A student with a heavy exam load tomorrow\n",
    "print(\"--- ðŸ“š GENERATING EXAM STUDY PLAN ---\")\n",
    "inputs = {\n",
    "    \"subjects\": [\"Linear Algebra\", \"Data Structures\", \"Economics\"],\n",
    "    \"hours_available\": 6\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" YOUR PLAN \" + \"=\"*20)\n",
    "print(result['study_plan'])\n",
    "print(\"=\"*51)\n",
    "\n",
    "# Scenario: A light weekend study session\n",
    "print(\"\\n\\n--- â˜• GENERATING WEEKEND REFRESHER PLAN ---\")\n",
    "inputs = {\n",
    "    \"subjects\": [\"Python Practice\", \"Reading Novel\"],\n",
    "    \"hours_available\": 2\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" YOUR PLAN \" + \"=\"*20)\n",
    "print(result['study_plan'])\n",
    "print(\"=\"*51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed3cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000151FC2CD7F0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31853687",
   "metadata": {},
   "source": [
    "## Advanced Ai Study Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d3e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœï¸ Planner: Generating schedule for 3 hours...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    141\u001b[39m inputs = {\n\u001b[32m    142\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msubjects\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mReact JS\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLinear Algebra\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    143\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhours_available\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m    144\u001b[39m }\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Recursion limit is safety for loops (stops it if it fails 20 times)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m final_state = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m20\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m FINAL PLAN \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m20\u001b[39m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28mprint\u001b[39m(final_state[\u001b[33m'\u001b[39m\u001b[33mfinal_output\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mplanner_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     33\u001b[39m prompt = ChatPromptTemplate.from_template(\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"You are a strict study scheduler.\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m    Task: Create a study plan for: {subjects}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m chain = prompt | llm\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msubjects\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhours\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhours_available\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeedback_instruction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeedback_instruction\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mstudy_plan\u001b[39m\u001b[33m\"\u001b[39m: response.content, \u001b[33m\"\u001b[39m\u001b[33mfeedback\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1025\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1019\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1020\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1029\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1030\u001b[39m         message=AIMessage(\n\u001b[32m   1031\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         generation_info=generation_info,\n\u001b[32m   1039\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:960\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    952\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    953\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    957\u001b[39m     **kwargs: Any,\n\u001b[32m    958\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    959\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1049\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1044\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1045\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1046\u001b[39m     **kwargs: Any,\n\u001b[32m   1047\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m   1048\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1055\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:947\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    946\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\ollama\\_client.py:181\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    178\u001b[39m   e.response.read()\n\u001b[32m    179\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpx\\_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpx\\_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91811\\Desktop\\langgraph\\sentiment_router\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. SETUP MODEL ---\n",
    "# Using Qwen 2.5 (0.5B) - Low temperature for strict logic\n",
    "llm = ChatOllama(model=\"qwen2.5:0.5b\", temperature=0.1)\n",
    "\n",
    "# --- 2. DEFINE STATE ---\n",
    "class StudyState(TypedDict):\n",
    "    subjects: List[str]\n",
    "    hours_available: float\n",
    "    study_plan: str\n",
    "    feedback: Optional[str]   # Error message from Reviewer\n",
    "    is_valid: bool            # Pass/Fail flag\n",
    "    final_output: str         # The plan + links combined\n",
    "\n",
    "# --- 3. DEFINE NODES ---\n",
    "\n",
    "def planner_node(state: StudyState):\n",
    "    print(f\"âœï¸ Planner: Generating schedule for {state['hours_available']} hours...\")\n",
    "    \n",
    "    subjects_str = \", \".join(state['subjects'])\n",
    "    feedback = state.get(\"feedback\", \"\")\n",
    "    \n",
    "    # If there is feedback (rejection), we add it to the prompt\n",
    "    feedback_instruction = \"\"\n",
    "    if feedback:\n",
    "        print(f\"   âš ï¸ Fixing previous error: {feedback}\")\n",
    "        feedback_instruction = f\"PREVIOUS ATTEMPT REJECTED. FEEDBACK: {feedback}. FIX THIS.\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are a strict study scheduler.\n",
    "        Task: Create a study plan for: {subjects}\n",
    "        Total Time Limit: {hours} hours.\n",
    "        {feedback_instruction}\n",
    "        \n",
    "        Constraints:\n",
    "        1. The total time of all sessions MUST sum up exactly to {hours} hours.\n",
    "        2. Break the time down into specific slots (e.g., \"10:00 - 11:00\").\n",
    "        3. Output ONLY the schedule text.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"subjects\": subjects_str, \n",
    "        \"hours\": state['hours_available'],\n",
    "        \"feedback_instruction\": feedback_instruction\n",
    "    })\n",
    "    \n",
    "    return {\"study_plan\": response.content, \"feedback\": None} # Clear old feedback\n",
    "\n",
    "def reviewer_node(state: StudyState):\n",
    "    print(\"ðŸ§ Reviewer: Checking the math...\")\n",
    "    plan = state[\"study_plan\"]\n",
    "    hours_limit = state[\"hours_available\"]\n",
    "    \n",
    "    # We ask the LLM to verify its own work (Self-Reflection)\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are a math auditor. \n",
    "        Review this study plan and sum up the total study hours listed.\n",
    "        \n",
    "        Plan:\n",
    "        {plan}\n",
    "        \n",
    "        Target Limit: {hours} hours.\n",
    "        \n",
    "        If the total time is significantly different from the target (more than 30 mins off), say \"FAIL\" and explain why.\n",
    "        If it is correct (or very close), say \"PASS\".\n",
    "        \n",
    "        Output format: PASS or FAIL: [Reason]\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"plan\": plan, \"hours\": hours_limit})\n",
    "    result = response.content.strip()\n",
    "    \n",
    "    if \"FAIL\" in result:\n",
    "        print(f\"   âŒ Review Rejected: {result}\")\n",
    "        return {\"is_valid\": False, \"feedback\": result}\n",
    "    else:\n",
    "        print(\"   âœ… Review Passed!\")\n",
    "        return {\"is_valid\": True}\n",
    "\n",
    "def resource_node(state: StudyState):\n",
    "    print(\"ðŸ”Ž Resource Finder: Fetching materials...\")\n",
    "    subjects = state[\"subjects\"]\n",
    "    plan = state[\"study_plan\"]\n",
    "    \n",
    "    # Since we can't browse the live web, we generate helpful search URLs\n",
    "    resources = []\n",
    "    for sub in subjects:\n",
    "        # Create a YouTube Search URL\n",
    "        query = sub.replace(\" \", \"+\")\n",
    "        url = f\"https://www.youtube.com/results?search_query={query}+tutorial\"\n",
    "        resources.append(f\"ðŸ“º {sub}: {url}\")\n",
    "        \n",
    "    resource_text = \"\\n\".join(resources)\n",
    "    \n",
    "    final_text = f\"{plan}\\n\\n--- ðŸ“š RECOMMENDED RESOURCES ---\\n{resource_text}\"\n",
    "    return {\"final_output\": final_text}\n",
    "\n",
    "# --- 4. DEFINE LOGIC (ROUTER) ---\n",
    "\n",
    "def route_decision(state: StudyState):\n",
    "    if state[\"is_valid\"]:\n",
    "        return \"resource_node\"\n",
    "    else:\n",
    "        return \"planner\" # Loop back!\n",
    "\n",
    "# --- 5. BUILD GRAPH ---\n",
    "\n",
    "workflow = StateGraph(StudyState)\n",
    "\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"reviewer\", reviewer_node)\n",
    "workflow.add_node(\"resource_node\", resource_node)\n",
    "\n",
    "workflow.set_entry_point(\"planner\")\n",
    "\n",
    "workflow.add_edge(\"planner\", \"reviewer\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"reviewer\",\n",
    "    route_decision,\n",
    "    {\n",
    "        \"resource_node\": \"resource_node\",\n",
    "        \"planner\": \"planner\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"resource_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- 6. RUN IT ---\n",
    "\n",
    "inputs = {\n",
    "    \"subjects\": [\"React JS\", \"Linear Algebra\"],\n",
    "    \"hours_available\": 3\n",
    "}\n",
    "\n",
    "# Recursion limit is safety for loops (stops it if it fails 20 times)\n",
    "final_state = app.invoke(inputs, config={\"recursion_limit\": 10})\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" FINAL PLAN \" + \"=\"*20)\n",
    "print(final_state['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e54e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
